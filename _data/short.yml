year: <p>The year a tool was first publicly released or discussed in an academic paper.</p>
platform: <p>The OS or software framework needed to run the tool.</p>
availability: <p>If the tool can be obtained by the public.</p>
license: <p>Tye type of license applied to the tool.</p>
venue: <p>The venue(s) for publications.</p>
hapticCategory: <p>The general types of haptic output devices controlled by the tool.</p>
use_case: <p>The primary purposes for which the tool was developed.</p>
hardwareAbstraction: |
  <p>How broad the type of hardware support is for a tool.</p>
  <ul>
  <li>Bespoke: Hardware is custom built, including open hardware.</li>
  <li>Consumer: Support is limited to a specific commercial device or a family of devices.</li>
  <li>Class: Any device with the same affordances can be used, possibly with some configuration required.</li>
  </ul>
device_names: <p>The hardware supported by the tool. This may be incomplete.</p>
body_position: <p>Parts of the body where stimuli are felt, if the tool explicitly shows this.</p>
drivingFeature: <p>If haptic content is controlled over time, by other actions, or both.</p>
effectLocalization: |
  <p>How the desired location of stimuli is mapped to the device.</p>
  <ul>
  <li>Device-centric: No spatial information is taken into acccount. Actuators are directly controlled.</li>
  <li>Target-centric: Stimuli are placed on the body or are assigned to a virtual object to be triggered through interaction. The tool handles how the device will display the effect.</li>
  <li>Location-aware: The desired location of an effect is taken into account to some extent, but is ultimately presented in context of the output device.</li>
  </ul>
mediaSupport: <p>Support for non-haptic media in the workspace, even if just to aid in manual synchronization.</p>
iterativePlayback: <p>If haptic effects can be played back from the tool to aid in the design process.</p>
designApproaches: |
  <p>Broadly, the methods available to create a desired effect.</p>
  <ul>
  <li>Direct parametric control (DPC): low-level parameters are directly modifiable.</li>
  <li>Process: parameters are controllable by an abstract process.</li>
  <li>Sequencing: reusable effects are ordered in time to create complex effects.</li>
  <li>Library: a library of pre-existing effects is available for use or re-use.</li>
  <li>Description: a natural language description of the experience is used to find an appropriate effect, often through searching a library.</li>
  </ul>
interactionMetaphors: |
  <p>Common UI metaphors that define how a user interacts with a tool.</p>
  <ul>
  <li>Track: a timeline represents an interactive channel containing effects.</li>
  <li>Keyframe: key points of the effect are set and behavior between them is interpolated.</li>
  <li>Score: an adaptation of a musical score or notation represents haptic effects.</li>
  <li>Dataflow: a dataflow programming model is used to control haptic output.</li>
  <li>Demonstration: physical actions or other data are mapped simply to effects or parameters.</li>
  <li>Generic Menu: typical GUI elements (e.g., sliders) are used to control effects with the absence of other metaphors.</li>
  </ul>
generalPurpose: <p>Meta-information about the tool.</p>
hardwareControl: <p>Aspects of the tool related to supported haptic hardware.</p>
iAndI: <p>Aspects of the tool related to the creation of haptic effects.</p>
storage: <p>How data is stored for import/export or internally to the software.</p>
connectivity: <p>How the tool can be extended to support new data, devices, and software.</p>
device_template: <p>Whether support can be easily extended to new types of devices.</p>
